# RAG iMessage Query System with Conversation Disentanglement Model

Unlock the hidden knowledge buried in your messages with semantic search that lets you query, analyze, and explore your conversations like never before.

---

## Project Introduction

This project enables natural language search through your iMessage history by chunking conversations and using vector embeddings for semantic retrieval. Built entirely local-first, all data stays on your machine with no external API calls.

<div align="center">
  <table>
    <tr>
      <td align="center">
        <b>Query Demo</b><br/>
        <img src="rag_demo.gif" width="550" alt="RAG Query Demo"/>
      </td>
      <td align="center">
        <b>Adding a Contact</b><br/>
        <img src="contact_preview.png" width="550" alt="Contact Add Preview"/>
      </td>
    </tr>
  </table>
</div>

---

## Table of Contents

- [ðŸ’¡ Overview](#-overview)
- [âœ¨ Features](#-features)
- [ðŸ—ï¸ Architecture](#ï¸-architecture)
  - [Conversation Chunking Algorithm](#conversation-chunking-algorithm)
  - [Contact-Based Partitioning](#contact-based-partitioning)
  - [Application Flow](#application-flow)
  - [ML Model Architecture](#ml-model-architecture)
- [Tech Stack](#tech-stack)
- [Getting Started](#getting-started)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
  - [Running the Application](#running-the-application)
  - [Project Structure](#project-structure)
- [License](#license)

---

## ðŸ’¡ Overview

RAGMessages is a powerful semantic search engine for your iMessage conversations, built using machine learning and vector embeddings. Designed to transform years of chat history into searchable knowledge, RAGMessages intelligently chunks conversations into threads and enables natural language queries to find specific discussions instantly. With a focus on privacy and performance, all processing happens locally on your machine.

## âœ¨ Features

- **Local-First Architecture**: All data stays on your machine, no external APIs
- **ML-Powered Chunking**: Neural network extracts conversation threads
- **Fast Semantic Search**: FAISS vector database enables sub-second retrieval across thousands of messages
- **Multi-Query Translation**: Generates multiple query variations to improve retrieval accuracy and recall
- **Contact-Based Partitioning**: Dedicated indexes for each conversation partner ensure faster, isolated searches
- **Interactive Chat Interface**: Chainlit-based UI for natural language queries and conversation discovery

## ðŸ—ï¸ Architecture

### Conversation Chunking Algorithm

RAGMessages uses a sophisticated **three-stage chunking pipeline** to segment message streams into coherent conversation threads:

**Stage 1: Time-Based Segmentation**
- Identifies **bursts**: rapid message exchanges within 5-minute windows
- Groups bursts into **sections**: conversation segments within 30-minute windows
- Applies semantic similarity checks to merge sections separated by longer gaps
- Prevents artificial splitting of continuous conversations

**Stage 2: Micro-Thread Extraction**
- Uses a trained neural network to identify fine-grained conversation threads
- Compares adjacent bursts using embedding similarity (threshold: 0.26)
- Scores potential threads with weighted combination: `0.5 * mean_score + 0.5 * max_score`
- Deduplicates messages by assigning each to the highest-scoring thread

**Stage 3: Remainder Assignment**
- Handles orphan messages not initially assigned to threads
- Applies time decay function to weight recent connections more heavily: `1 / (1 + exp(0.0114 * (hours - 168)))`
- Inserts remainders chronologically into best-matching threads
- Ensures complete conversation coverage with zero message loss

### Contact-Based Partitioning

Each conversation partner gets a dedicated FAISS vector index:
- **Isolated Search Spaces**: Queries only search relevant conversations
- **Faster Retrieval**: Smaller indexes mean sub-second search times
- **Scalable Design**: Add new contacts without rebuilding existing indexes
- **Privacy-Preserving**: Each contact's data remains separate

### Application Flow

```
1. User Input
   â””â”€ Enter contact phone number

2. Data Extraction
   â””â”€ Query macOS chat.db (~/Library/Messages/chat.db)
   â””â”€ Extract messages with flexible phone number matching
   â””â”€ Decode attributedBody blobs for complete content

3. Conversation Processing
   â””â”€ Apply three-stage chunking algorithm
   â””â”€ Convert message tuples into conversation threads
   â””â”€ Format threads with timestamps and sender labels

4. Embedding & Indexing
   â””â”€ Embed threads using multi-qa-MiniLM-L6-cos-v1 (384-dim)
   â””â”€ Create FAISS IndexFlatL2 for exact similarity search
   â””â”€ Store index with metadata for retrieval mapping

5. Semantic Search
   â””â”€ User submits natural language query
   â””â”€ Generate multiple query variations via multi-query translation
   â””â”€ Embed all query variations and search FAISS index
   â””â”€ Aggregate and deduplicate results from all queries
   â””â”€ Retrieve top-k most relevant conversation threads
   â””â”€ Display results with context and timestamps
```

### ML Model Architecture

**Conversation Disentanglement Neural Network**

The ML model is integrated into the chunking pipeline to extract micro-threads from message bursts.

```
Input: Message Embeddings [batch_size, num_messages, 768]
   â†“
Self-Attention Layer:
   â”œâ”€ 4 attention heads learn message relationships
   â”‚  â””â”€ Temporal proximity, semantic similarity, speaker patterns, reply-to relationships
   â””â”€ Residual connection: output = input + attention(input)
   â†“
Shared Backbone:
   â”œâ”€ Linear(768 â†’ 256) + ReLU + Dropout(0.2)
   â”œâ”€ Linear(256 â†’ 128) + ReLU + Dropout(0.2)
   â””â”€ Linear(128 â†’ 64)  + ReLU + Dropout(0.2)
   â†“
Dual Output Heads:
   â”œâ”€ Rank Head: Scores message relevance (ListNetLoss)
   â””â”€ Keep Head: Binary inclusion decision (BCELoss)
```

**Training Details**
- **Dataset**: IRC Disentanglement Dataset (human-annotated chat logs)
- **Training Strategy**: Iterative thread prediction with teacher forcing
- **Optimizer**: Adam (learning rate: 0.001)
- **Configuration**: 30 epochs, batch size 5

**Performance Metrics**
- **Rank Head F1**: 0.809 (primary thread predictor)
- **Keep Head F1**: 0.549 (false positive filter)
- **Combined Specificity**: 0.799 (accurately excludes non-thread messages)

**Integration**
- Embedded in `chunk_algorithm/micro_thread.py`
- Processes bursts to identify conversation threads
- Handles interleaved conversations and multi-topic exchanges
- Enables accurate thread extraction without rule-based heuristics

---

## Tech Stack

### Backend

**Data Extraction**
- **SQLite3**: Direct integration with macOS iMessage database
- **Python 3.8+**: Core data processing and pipeline orchestration

**Chunking & Processing**
- **SentenceTransformers**: Message embedding for similarity calculations
  - Chunking model: `all-MiniLM-L6-v2` (384-dim)
  - RAG model: `multi-qa-MiniLM-L6-cos-v1` (384-dim, asymmetric search optimized)
- **PyTorch**: Tensor operations for embedding comparisons
- **NumPy**: Numerical computations for time decay and scoring

**Vector Search**
- **FAISS**: High-performance vector similarity search
  - Index type: `IndexFlatL2` (exact L2 distance)
  - Per-contact index architecture

### Frontend

**User Interface**
- **Chainlit**: Interactive chat interface for queries and results
- **Markdown Rendering**: Formatted conversation thread display

### Dependencies
```
torch>=2.0.0
sentence-transformers>=2.2.0
faiss-cpu>=1.7.4
chainlit>=1.0.0
numpy>=1.24.0
scikit-learn>=1.3.0
```

---

## Getting Started

### Prerequisites

- **macOS**: Required for access to iMessage database
- **Python 3.8+**: Core runtime environment
- **Full Disk Access**: Terminal needs permission to read chat.db

### Installation

```bash
# Clone the repository
git clone https://github.com/prestonrank/RAGMessages.git
cd RAGMessages

# Install dependencies
pip install -r requirements.txt

# Grant Full Disk Access
# 1. Open System Settings â†’ Privacy & Security â†’ Full Disk Access
# 2. Add Terminal (or your terminal emulator)
# 3. Restart terminal
```

### Running the Application

```bash
# Launch the web interface
cd chainlit_app
chainlit run app.py

# Navigate to http://localhost:8000
# Enter contact phone number and start querying
```

### Project Structure

```
RAGMessages/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â”œâ”€â”€ message_loader.py      # SQLite database interface
â”‚   â”‚   â”œâ”€â”€ file.py                # Message formatting utilities
â”‚   â”‚   â””â”€â”€ test_data.py           # Sample conversation data
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ chat.db                # macOS iMessage database
â”‚
â”œâ”€â”€ chunk_algorithm/
â”‚   â”œâ”€â”€ chunking.py                # Main orchestrator
â”‚   â”œâ”€â”€ topic_shift.py             # Stage 1: Time-based segmentation
â”‚   â”œâ”€â”€ micro_thread.py            # Stage 2: ML-powered thread extraction
â”‚   â”œâ”€â”€ remainder.py               # Stage 3: Orphan assignment
â”‚   â””â”€â”€ similarity.py              # Embedding similarity utilities
â”‚
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ rag.py                     # FAISS indexing and retrieval
â”‚   â”œâ”€â”€ app.py                     # Chainlit UI
â”‚   â””â”€â”€ main.ipynb                 # Experimental notebook
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ CD_model.py                # Neural network architecture
â”‚   â”œâ”€â”€ training_loop.py           # Training logic with teacher forcing
â”‚   â”œâ”€â”€ loss_function.py           # ListNetLoss implementation
â”‚   â”œâ”€â”€ dataset_utils.py           # IRC dataset loading
â”‚   â””â”€â”€ construct_tree.py          # Message tree construction
â”‚
â””â”€â”€ proj_docs/
    â”œâ”€â”€ proj_doc.md                # Development history
    â”œâ”€â”€ algorithm_doc.md           # Detailed chunking approach
    â””â”€â”€ baseline.md                # Baseline comparison
```

---

## License

MIT License - See LICENSE file for details.

### Citation

If you use this work in your research or projects, please cite:

```bibtex
@misc{ragmessages-2025,
  author = {Preston Rank},
  title = {RAGMessages: Semantic Search for iMessage Conversations},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/prestonrank/RAGMessages}
}
```
